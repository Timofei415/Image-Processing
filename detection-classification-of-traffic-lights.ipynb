{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":19340,"sourceType":"datasetVersion","datasetId":14302},{"sourceId":3771012,"sourceType":"datasetVersion","datasetId":2252446},{"sourceId":21508197,"sourceType":"kernelVersion"}],"dockerImageVersionId":29661,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom glob import glob\nimport sys\nimport sklearn.metrics as metrics","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-10T05:40:43.058629Z","iopub.execute_input":"2022-06-10T05:40:43.058932Z","iopub.status.idle":"2022-06-10T05:40:45.67726Z","shell.execute_reply.started":"2022-06-10T05:40:43.058882Z","shell.execute_reply":"2022-06-10T05:40:45.676181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is needed to display the images.\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:40:45.680714Z","iopub.execute_input":"2022-06-10T05:40:45.684095Z","iopub.status.idle":"2022-06-10T05:40:45.692868Z","shell.execute_reply.started":"2022-06-10T05:40:45.681049Z","shell.execute_reply":"2022-06-10T05:40:45.691767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detect the traffic lights in an image","metadata":{}},{"cell_type":"markdown","source":"### Download pretrained model","metadata":{}},{"cell_type":"code","source":"# What model to download.\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\nMODEL_FILE = MODEL_NAME + '.tar.gz'\nDOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n\n# Path to frozen detection graph. This is the actual model that is used for the object detection.\nmodel_path = \"./\"\nPATH_TO_CKPT = model_path + MODEL_NAME + '/frozen_inference_graph.pb'\n\n\ndef download_model():\n    import six.moves.urllib as urllib\n    import tarfile\n\n    opener = urllib.request.URLopener()\n    opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n    tar_file = tarfile.open(MODEL_FILE)\n    for file in tar_file.getmembers():\n        file_name = os.path.basename(file.name)\n        if 'frozen_inference_graph.pb' in file_name:\n            tar_file.extract(file, os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:40:50.934111Z","iopub.execute_input":"2022-06-10T05:40:50.934438Z","iopub.status.idle":"2022-06-10T05:40:50.942346Z","shell.execute_reply.started":"2022-06-10T05:40:50.934388Z","shell.execute_reply":"2022-06-10T05:40:50.941457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Code for detection","metadata":{}},{"cell_type":"code","source":"def load_graph():\n    if not os.path.exists(PATH_TO_CKPT):\n        download_model()\n\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n\n    return detection_graph\n\ndef select_boxes(boxes, classes, scores, score_threshold=0, target_class=10):\n    \"\"\"\n\n    :param boxes:\n    :param classes:\n    :param scores:\n    :param target_class: default traffic light id in COCO dataset is 10\n    :return:\n    \"\"\"\n\n    sq_scores = np.squeeze(scores)\n    sq_classes = np.squeeze(classes)\n    sq_boxes = np.squeeze(boxes)\n\n    sel_id = np.logical_and(sq_classes == target_class, sq_scores > score_threshold)\n\n    return sq_boxes[sel_id]\n\nclass TLClassifier(object):\n    def __init__(self):\n\n        self.detection_graph = load_graph()\n        self.extract_graph_components()\n        self.sess = tf.Session(graph=self.detection_graph)\n\n        # run the first session to \"warm up\"\n        dummy_image = np.zeros((100, 100, 3))\n        self.detect_multi_object(dummy_image,0.1)\n        self.traffic_light_box = None\n        self.classified_index = 0\n\n    def extract_graph_components(self):\n        # Definite input and output Tensors for detection_graph\n        self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n        # Each box represents a part of the image where a particular object was detected.\n        self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n        # Each score represent how level of confidence for each of the objects.\n        # Score is shown on the result image, together with the class label.\n        self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n        self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n        self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n    \n    def detect_multi_object(self, image_np, score_threshold):\n        \"\"\"\n        Return detection boxes in a image\n\n        :param image_np:\n        :param score_threshold:\n        :return:\n        \"\"\"\n\n        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n        image_np_expanded = np.expand_dims(image_np, axis=0)\n        # Actual detection.\n\n        (boxes, scores, classes, num) = self.sess.run(\n            [self.detection_boxes, self.detection_scores, self.detection_classes, self.num_detections],\n            feed_dict={self.image_tensor: image_np_expanded})\n\n        sel_boxes = select_boxes(boxes=boxes, classes=classes, scores=scores,\n                                 score_threshold=score_threshold, target_class=10)\n\n        return sel_boxes\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:40:52.492664Z","iopub.execute_input":"2022-06-10T05:40:52.49298Z","iopub.status.idle":"2022-06-10T05:40:52.605946Z","shell.execute_reply.started":"2022-06-10T05:40:52.492926Z","shell.execute_reply":"2022-06-10T05:40:52.605131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tlc=TLClassifier()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:40:54.256949Z","iopub.execute_input":"2022-06-10T05:40:54.257304Z","iopub.status.idle":"2022-06-10T05:41:09.684699Z","shell.execute_reply.started":"2022-06-10T05:40:54.257249Z","shell.execute_reply":"2022-06-10T05:41:09.683858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_roi_image(image_np, sel_box):\n    im_height, im_width, _ = image_np.shape\n    (left, right, top, bottom) = (sel_box[1] * im_width, sel_box[3] * im_width,\n                                  sel_box[0] * im_height, sel_box[2] * im_height)\n    cropped_image = image_np[int(top):int(bottom), int(left):int(right), :]\n    return cropped_image","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:09.686629Z","iopub.execute_input":"2022-06-10T05:41:09.686918Z","iopub.status.idle":"2022-06-10T05:41:09.696021Z","shell.execute_reply.started":"2022-06-10T05:41:09.686871Z","shell.execute_reply":"2022-06-10T05:41:09.695105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\ntest_file = \"../input/lisa-traffic-light-dataset/daySequence1/daySequence1/frames/daySequence1--02000.jpg\"\n# test_file = \"/kaggle/input/lisa-traffic-light-dataset/sample-dayClip6/sample-dayClip6/frames/dayClip6--00332.jpg\"\nfrom PIL import Image\nim = Image.open(test_file)\nimage_np = np.asarray(im)\nplt.imshow(image_np)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:18:42.074858Z","iopub.execute_input":"2022-06-10T07:18:42.075209Z","iopub.status.idle":"2022-06-10T07:18:42.351545Z","shell.execute_reply.started":"2022-06-10T07:18:42.075142Z","shell.execute_reply":"2022-06-10T07:18:42.350786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\nboxes=tlc.detect_multi_object(image_np,score_threshold=0.2)\nif len(boxes)>0:\n    cropped_image=crop_roi_image(image_np,boxes[0])\n    plt.imshow(cropped_image)\n    immmm = Image.fromarray(cropped_image)\n    immmm.save('./temp.jpg')\nelse:\n    print('No traffic light was detected or light is off')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:18:44.594733Z","iopub.execute_input":"2022-06-10T07:18:44.59524Z","iopub.status.idle":"2022-06-10T07:18:44.803097Z","shell.execute_reply.started":"2022-06-10T07:18:44.595014Z","shell.execute_reply":"2022-06-10T07:18:44.802027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CLASSIFICATION","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:12.522548Z","iopub.execute_input":"2022-06-10T05:41:12.522861Z","iopub.status.idle":"2022-06-10T05:41:12.537858Z","shell.execute_reply.started":"2022-06-10T05:41:12.522809Z","shell.execute_reply":"2022-06-10T05:41:12.536646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224]","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:13.441429Z","iopub.execute_input":"2022-06-10T05:41:13.441734Z","iopub.status.idle":"2022-06-10T05:41:13.446759Z","shell.execute_reply.started":"2022-06-10T05:41:13.441684Z","shell.execute_reply":"2022-06-10T05:41:13.445829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning","metadata":{}},{"cell_type":"code","source":"inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:15.076638Z","iopub.execute_input":"2022-06-10T05:41:15.076956Z","iopub.status.idle":"2022-06-10T05:41:28.381651Z","shell.execute_reply.started":"2022-06-10T05:41:15.0769Z","shell.execute_reply":"2022-06-10T05:41:28.380795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in inception.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.384569Z","iopub.execute_input":"2022-06-10T05:41:28.385089Z","iopub.status.idle":"2022-06-10T05:41:28.398457Z","shell.execute_reply.started":"2022-06-10T05:41:28.385019Z","shell.execute_reply":"2022-06-10T05:41:28.397543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(inception.output)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.40119Z","iopub.execute_input":"2022-06-10T05:41:28.401519Z","iopub.status.idle":"2022-06-10T05:41:28.581978Z","shell.execute_reply.started":"2022-06-10T05:41:28.401454Z","shell.execute_reply":"2022-06-10T05:41:28.581171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/cropped-lisa-traffic-light-dataset/cropped_lisa_1/train_1'\nvalid_path = '../input/cropped-lisa-traffic-light-dataset/cropped_lisa_1/val_1'","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.585097Z","iopub.execute_input":"2022-06-10T05:41:28.585622Z","iopub.status.idle":"2022-06-10T05:41:28.590336Z","shell.execute_reply.started":"2022-06-10T05:41:28.585565Z","shell.execute_reply":"2022-06-10T05:41:28.589316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folders = glob(train_path+'/*')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.594339Z","iopub.execute_input":"2022-06-10T05:41:28.594813Z","iopub.status.idle":"2022-06-10T05:41:28.60577Z","shell.execute_reply.started":"2022-06-10T05:41:28.594759Z","shell.execute_reply":"2022-06-10T05:41:28.605065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = Dense(len(folders), activation='softmax')(x)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.607358Z","iopub.execute_input":"2022-06-10T05:41:28.607839Z","iopub.status.idle":"2022-06-10T05:41:28.633751Z","shell.execute_reply.started":"2022-06-10T05:41:28.607627Z","shell.execute_reply":"2022-06-10T05:41:28.632959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(inputs=inception.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.635277Z","iopub.execute_input":"2022-06-10T05:41:28.635801Z","iopub.status.idle":"2022-06-10T05:41:28.684901Z","shell.execute_reply.started":"2022-06-10T05:41:28.635564Z","shell.execute_reply":"2022-06-10T05:41:28.684212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.68638Z","iopub.execute_input":"2022-06-10T05:41:28.686659Z","iopub.status.idle":"2022-06-10T05:41:28.802988Z","shell.execute_reply.started":"2022-06-10T05:41:28.686614Z","shell.execute_reply":"2022-06-10T05:41:28.802272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.804595Z","iopub.execute_input":"2022-06-10T05:41:28.80504Z","iopub.status.idle":"2022-06-10T05:41:28.810807Z","shell.execute_reply.started":"2022-06-10T05:41:28.804854Z","shell.execute_reply":"2022-06-10T05:41:28.809907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set = train_datagen.flow_from_directory(train_path,\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical',\n                                                 shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:28.812402Z","iopub.execute_input":"2022-06-10T05:41:28.813065Z","iopub.status.idle":"2022-06-10T05:41:49.214883Z","shell.execute_reply.started":"2022-06-10T05:41:28.812777Z","shell.execute_reply":"2022-06-10T05:41:49.213985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_set = test_datagen.flow_from_directory(valid_path,\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical',\n                                            shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:49.216425Z","iopub.execute_input":"2022-06-10T05:41:49.217002Z","iopub.status.idle":"2022-06-10T05:41:51.798866Z","shell.execute_reply.started":"2022-06-10T05:41:49.216946Z","shell.execute_reply":"2022-06-10T05:41:51.798046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(training_set.class_indices)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:51.803943Z","iopub.execute_input":"2022-06-10T05:41:51.806245Z","iopub.status.idle":"2022-06-10T05:41:51.815211Z","shell.execute_reply.started":"2022-06-10T05:41:51.806163Z","shell.execute_reply":"2022-06-10T05:41:51.814363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = model.fit_generator(\n  training_set,\n  validation_data=val_set,\n  epochs=10,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(val_set)\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T05:41:51.820787Z","iopub.execute_input":"2022-06-10T05:41:51.822211Z","iopub.status.idle":"2022-06-10T06:46:51.43878Z","shell.execute_reply.started":"2022-06-10T05:41:51.82216Z","shell.execute_reply":"2022-06-10T06:46:51.43687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(r.history['acc'], label='train acc')\nplt.plot(r.history['val_acc'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T06:46:59.746612Z","iopub.execute_input":"2022-06-10T06:46:59.746938Z","iopub.status.idle":"2022-06-10T06:47:00.0345Z","shell.execute_reply.started":"2022-06-10T06:46:59.746885Z","shell.execute_reply":"2022-06-10T06:47:00.033419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-06-10T06:47:06.602895Z","iopub.execute_input":"2022-06-10T06:47:06.603216Z","iopub.status.idle":"2022-06-10T06:47:06.609302Z","shell.execute_reply.started":"2022-06-10T06:47:06.603161Z","shell.execute_reply":"2022-06-10T06:47:06.608208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ndef true_and_predicted_labels(dataset):\n    labels = np.zeros((dataset.n,7))\n    preds = np.zeros_like(labels)\n    for i in range(len(dataset)):\n        sys.stdout.write('evaluating batch {}\\r'.format(i))\n        sys.stdout.flush()\n        batch = dataset[i]\n        batch_images = batch[0]\n        batch_labels = batch[1]\n        batch_preds = model.predict(batch_images)\n        start = i*batch_size\n        labels[start:start+batch_size] = batch_labels\n        preds[start:start+batch_size] = batch_preds\n    return labels, preds\n\nval_labels, val_preds = true_and_predicted_labels(val_set)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T06:47:15.502504Z","iopub.execute_input":"2022-06-10T06:47:15.502813Z","iopub.status.idle":"2022-06-10T06:47:30.310989Z","shell.execute_reply.started":"2022-06-10T06:47:15.502763Z","shell.execute_reply":"2022-06-10T06:47:30.309971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = val_preds\nidx = np.argmax(a, axis=-1)\na = np.zeros( a.shape )\na[ np.arange(a.shape[0]), idx] = 1","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:06:28.32119Z","iopub.execute_input":"2022-06-10T07:06:28.321508Z","iopub.status.idle":"2022-06-10T07:06:28.3268Z","shell.execute_reply.started":"2022-06-10T07:06:28.321459Z","shell.execute_reply":"2022-06-10T07:06:28.32607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(val_labels, a))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:08:32.779357Z","iopub.execute_input":"2022-06-10T07:08:32.77967Z","iopub.status.idle":"2022-06-10T07:08:32.808688Z","shell.execute_reply.started":"2022-06-10T07:08:32.779614Z","shell.execute_reply":"2022-06-10T07:08:32.807799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(val_labels.argmax(axis=1), a.argmax(axis=1)))","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:08:19.180715Z","iopub.execute_input":"2022-06-10T07:08:19.181017Z","iopub.status.idle":"2022-06-10T07:08:19.194223Z","shell.execute_reply.started":"2022-06-10T07:08:19.180964Z","shell.execute_reply":"2022-06-10T07:08:19.192933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\ncf_matrix = confusion_matrix(val_labels.argmax(axis=1), a.argmax(axis=1))\nsns.heatmap(cf_matrix, annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:17:21.314841Z","iopub.execute_input":"2022-06-10T07:17:21.315183Z","iopub.status.idle":"2022-06-10T07:17:21.833028Z","shell.execute_reply.started":"2022-06-10T07:17:21.315121Z","shell.execute_reply":"2022-06-10T07:17:21.832161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = './temp.jpg'\n\nimage = tf.keras.preprocessing.image.load_img(test_img)\nim1 = image.resize((224, 224), Image.ANTIALIAS)\ninput_arr = tf.keras.preprocessing.image.img_to_array(im1)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npredictions = model.predict(input_arr)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:12:39.999986Z","iopub.execute_input":"2022-06-10T07:12:40.000321Z","iopub.status.idle":"2022-06-10T07:12:40.22169Z","shell.execute_reply.started":"2022-06-10T07:12:40.000266Z","shell.execute_reply":"2022-06-10T07:12:40.220789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_class_names = training_set.class_indices\nall_class_names","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:12:44.805673Z","iopub.execute_input":"2022-06-10T07:12:44.806003Z","iopub.status.idle":"2022-06-10T07:12:44.812225Z","shell.execute_reply.started":"2022-06-10T07:12:44.805948Z","shell.execute_reply":"2022-06-10T07:12:44.811431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_pred = predictions.argmax() \nkey_list = list(all_class_names.keys())\nval_list = list(all_class_names.values())\nposition = val_list.index(pos_pred)\nprint(key_list[position])\nplt.imshow(cropped_image)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T07:18:50.831006Z","iopub.execute_input":"2022-06-10T07:18:50.831338Z","iopub.status.idle":"2022-06-10T07:18:50.983009Z","shell.execute_reply.started":"2022-06-10T07:18:50.831287Z","shell.execute_reply":"2022-06-10T07:18:50.982248Z"},"trusted":true},"execution_count":null,"outputs":[]}]}